{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6b4f74-6f33-417e-a1b7-af93c7bec755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9d51c2-dfab-48c6-a278-7b701736c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout,Flatten, add,Dot,Concatenate,GRU\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ae1a01-af9c-485f-b53e-f230403e8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pickle.load( open('labels.pkl', 'rb'))\n",
    "features=pickle.load( open('features.pkl', 'rb'))\n",
    "features_tfidf= pickle.load( open('features_tfidf.pkl', 'rb'))\n",
    "word_tfidf_weights=pickle.load( open('word_tfidf_weights.pkl', 'rb'))\n",
    "non_text_features_np = features.drop(columns=['title', 'text', 'combined_text', 'label']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6087565a-09f2-41d1-88b9-d32607b31afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9eade7d-ea11-4494-904e-5080e66f1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Preprocessing\n",
    "train_texts = features[\"combined_text\"]\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)  # train_texts is a list of input texts\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ceef90-cc4f-4696-9623-b929845f2237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (45783, 400)\n",
      "Validation set shape: (11446, 400)\n",
      "Test set shape: (14308, 400)\n"
     ]
    }
   ],
   "source": [
    "train_ft,test_ft,train_labels,test_labels=train_test_split(train_data,labels,test_size=0.2, train_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_ft, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", test_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fddf34-78de-4c62-9c04-e0f82dd8b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (45783, 15)\n",
      "Validation set shape: (11446, 15)\n",
      "Test set shape: (14308, 15)\n"
     ]
    }
   ],
   "source": [
    "train_txt_ft,test_txt_ft,train_txt_labels,test_txt_labels=train_test_split(non_text_features_np,labels,test_size=0.2, train_size=0.8)\n",
    "X_txt_train, X_txt_val, y_txt_train, y_txt_val = train_test_split(train_txt_ft, train_txt_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_txt_train.shape)\n",
    "print(\"Validation set shape:\", X_txt_val.shape)\n",
    "print(\"Test set shape:\", test_txt_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1291036-4ecc-44a4-8a5c-23861f006777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generator to get data in batch (avoids session crash)\n",
    "def data_generator(ft,txt batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for i,key in enumerate(ft):\n",
    "            n += 1\n",
    "            X1.append(features[key][0])\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield [X1, X2], y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814d1106-6207-4fdc-804d-5fec43552f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# encoder model\n",
    "# image feature layers\n",
    "inputs1 = Input(shape=(15,))\n",
    "fe1 = Dropout(0.4)(inputs1)\n",
    "fe2 = Dense(32, activation='relu')(fe1)\n",
    "# sequence feature layers\n",
    "inputs2 = Input(shape=(400,))\n",
    "se1 = Embedding(vocab_size, 128, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = GRU(32)(se2)\n",
    "\n",
    "# decoder model\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(32, activation='relu')(decoder1)\n",
    "outputs = tf.keras.layers.Flatten()(decoder2)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "modelg = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "modelg.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "# plot the model\n",
    "plot_model(modelg, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ebecc03-2740-406f-8842-bbd1c56371c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 400, 128)     44658816    ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 15)           0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 400, 128)     0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 32)           512         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 32)           15552       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32)           0           ['dense_10[0][0]',               \n",
      "                                                                  'gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 32)           1056        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 32)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            33          ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,675,969\n",
      "Trainable params: 44,675,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(modelg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dba5339-3e50-4034-8bd3-42edf63b0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "174/174 [==============================] - 982s 6s/step - loss: 5.6017 - val_loss: 0.3328\n",
      "Epoch 2/3\n",
      "174/174 [==============================] - 1105s 6s/step - loss: 0.4015 - val_loss: 0.2507\n",
      "Epoch 3/3\n",
      "174/174 [==============================] - 1282s 7s/step - loss: 0.2648 - val_loss: 0.2695\n"
     ]
    }
   ],
   "source": [
    "history=modelg.fit([X_txt_train,X_train], y_train, epochs=3, batch_size=264, validation_data=([X_txt_val,X_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aaec9f2-d3d7-46e8-8ad1-96b613ace73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0d10f-a9dd-49f7-8338-3765da2a7767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
