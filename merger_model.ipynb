{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b420121-b4b4-4cd3-b131-88c6766e4243",
   "metadata": {},
   "source": [
    "# <center> Merger Model Architecture </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e4f6b23-5599-40f9-8869-3412ec1368b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout,Flatten,add,Dot,GRU\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e137f77-2a11-4fda-abf0-99f2fa7591a8",
   "metadata": {},
   "source": [
    "# Loading Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ae1a01-af9c-485f-b53e-f230403e8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pickle.load( open('labels.pkl', 'rb'))\n",
    "features=pickle.load( open('features.pkl', 'rb'))\n",
    "features_tfidf= pickle.load( open('features_tfidf.pkl', 'rb'))\n",
    "word_tfidf_weights=pickle.load( open('word_tfidf_weights.pkl', 'rb'))\n",
    "non_text_features_np = features.drop(columns=['title', 'text', 'combined_text', 'label']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a282424-6642-4567-b3a1-c1fc836a373d",
   "metadata": {},
   "source": [
    "# Generating Seqeuences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9eade7d-ea11-4494-904e-5080e66f1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = features[\"combined_text\"]\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)  # train_texts is a list of input texts\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=400)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79596668-c28e-493e-a0b5-a0251dd05ec8",
   "metadata": {},
   "source": [
    "## Input - 1 Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ceef90-cc4f-4696-9623-b929845f2237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (45783, 400)\n",
      "Validation set shape: (11446, 400)\n",
      "Test set shape: (14308, 400)\n"
     ]
    }
   ],
   "source": [
    "train_ft,test_ft,train_labels,test_labels=train_test_split(train_data,labels,test_size=0.2, train_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_ft, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", test_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cb8c8-c97a-4993-b634-8391f0dec9b2",
   "metadata": {},
   "source": [
    "## Input - 1 Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fddf34-78de-4c62-9c04-e0f82dd8b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (45783, 15)\n",
      "Validation set shape: (11446, 15)\n",
      "Test set shape: (14308, 15)\n"
     ]
    }
   ],
   "source": [
    "train_txt_ft,test_txt_ft,train_txt_labels,test_txt_labels=train_test_split(non_text_features_np,labels,test_size=0.2, train_size=0.8)\n",
    "X_txt_train, X_txt_val, y_txt_train, y_txt_val = train_test_split(train_txt_ft, train_txt_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_txt_train.shape)\n",
    "print(\"Validation set shape:\", X_txt_val.shape)\n",
    "print(\"Test set shape:\", test_txt_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724842e-3c41-4cba-825a-83184c732cc4",
   "metadata": {},
   "source": [
    "# Merger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8da7b78-c58a-40c4-b840-4d5760022460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Merger_Model(Model):\n",
    "    def __init__(self,vocab_size):\n",
    "        super(Merger_Model,self).__init__()\n",
    "        #self.input_1= Input(shape=(15,))\n",
    "        self.input_1_dropout= Dropout(0.4)\n",
    "        self.input_1_dense= Dense(32,activation=\"relu\")\n",
    "        \n",
    "        #self.input_2=Input(shape=(400,))\n",
    "        self.input_2_embed= Embedding(vocab_size,128)\n",
    "        self.input_2_dropout= Dropout(0.3)\n",
    "        self.input_2_GRU = GRU(32)\n",
    "        \n",
    "        self.merge_output= Dense(32, activation=\"relu\")\n",
    "        self.flatten= Flatten()\n",
    "        self.output_1= Dense(1,activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        #print(inputs)\n",
    "        #print(inputs[0].shape,inputs[1].shape)\n",
    "        #x1=self.input_1(inputs[0])\n",
    "        x1=self.input_1_dropout(inputs[0])\n",
    "        x1=self.input_1_dense(x1)\n",
    "        \n",
    "       # x2=self.input_2(inputs[1])\n",
    "        x2=self.input_2_embed(inputs[1])\n",
    "        x2=self.input_2_dropout(x2)\n",
    "        x2=self.input_2_GRU(x2)\n",
    "        \n",
    "        x3=add([x1,x2])\n",
    "        x3=self.merge_output(x3)\n",
    "        x3=self.flatten(x3)\n",
    "        x3=self.output_1(x3)\n",
    "        \n",
    "        return x3\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aff852b3-6c7b-4cef-93ca-bb8f49144389",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=Merger_Model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d32ec60-a402-427b-861b-a43a5c0c138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.build([(None,15),(None,400)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ab854b9-2906-4f53-ab82-571bae9d4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"merger__model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_27 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            multiple                  512       \n",
      "                                                                 \n",
      " embedding_13 (Embedding)    multiple                  44658816  \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " gru_13 (GRU)                multiple                  15552     \n",
      "                                                                 \n",
      " dense_39 (Dense)            multiple                  1056      \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,675,969\n",
      "Trainable params: 44,675,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merge.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bedbe-5dc6-42ba-8ac4-aac6ae060e74",
   "metadata": {},
   "source": [
    "## Configuring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b73a1c8-4c9b-4ba0-bdd0-ce0e8208ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=keras.optimizers.Adam(learning_rate=0.001)\n",
    "merge.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "save_model=tf.keras.callbacks.ModelCheckpoint(\"merger_model\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c085a7f-28e3-4192-9956-ffd3d337ca91",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b93aa13e-609e-4bc9-acbe-a5962efa01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.9663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: merger_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: merger_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 244s 1s/step - loss: 0.3276 - accuracy: 0.9663 - val_loss: 0.3721 - val_accuracy: 0.9366\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: merger_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: merger_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 264s 2s/step - loss: 0.1200 - accuracy: 0.9796 - val_loss: 0.3655 - val_accuracy: 0.9393\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 262s 2s/step - loss: 0.0806 - accuracy: 0.9862 - val_loss: 0.4037 - val_accuracy: 0.9381\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 252s 1s/step - loss: 0.0935 - accuracy: 0.9848 - val_loss: 0.4248 - val_accuracy: 0.9344\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 259s 1s/step - loss: 0.0753 - accuracy: 0.9876 - val_loss: 0.4901 - val_accuracy: 0.9319\n"
     ]
    }
   ],
   "source": [
    "history=merge.fit(\n",
    "    [X_txt_train,X_train],\n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=264, \n",
    "    validation_data=([X_txt_val,X_val],y_val),\n",
    "    callbacks=[save_model,early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a9dc5-8cea-4a62-840d-76bc4ee9a8e8",
   "metadata": {},
   "source": [
    "## loading and predicting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b4bb517-db4a-4902-a1b3-ecd664688087",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_merger=tf.keras.models.load_model(\"merger_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ab5a622-c1a3-47be-bb22-091bf988bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 14s 31ms/step - loss: 0.3431 - accuracy: 0.9430\n",
      " Accuracy : 94.29689645767212 \n",
      " Loss : 0.343141108751297\n"
     ]
    }
   ],
   "source": [
    "metrics=loaded_merger.evaluate([test_txt_ft,test_ft],test_labels)\n",
    "print(f\" Accuracy : {metrics[1]*100} \\n Loss : {metrics[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aaec9f2-d3d7-46e8-8ad1-96b613ace73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507c414-1ce2-414e-9c75-8b58ef8b7022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
